f.write("\n(b) ******* Confusion Matrix ******\n")
cm = confusion_matrix(y_test, ys2_pred)
confusion_mat = pd.DataFrame(cm, index=x_labels)
f.write(tabulate(confusion_mat, x_labels, tablefmt="grid", stralign="center") +"\n")

    # Task 1.7 c 
class_report = classification_report(y_test, ys2_pred, target_names=bbc_data.target_names)
f.write("\n(c) ****** Precision, recall, and F1-measure for each class *******\n")
#Index = [''], because we has to LHS values to put
class_repo = pd.DataFrame({class_report},index = [''])
f.write(tabulate(class_repo, tablefmt="grid", stralign="right", numalign="right"))

    # Task 1.7 d
f.write("\n\n(d) ****** Accuracy, Macro-average F1 and Weighted-average F1 of the model *******\n")
headers = ["Accuracy_score", "Macro-average F1", "Weighted-average F1"]
acc_score = metrics.accuracy_score(y_test, ys2_pred)
f1_macroavg = f1_score(y_test, ys2_pred, average='macro')
f1_weightedavg = f1_score(y_test, ys2_pred, average='weighted')
f1_scores = pd.DataFrame({acc_score, f1_macroavg, f1_weightedavg}, index=headers)
f.write(tabulate(f1_scores, tablefmt = "grid"))

    # Task 1.7 e

f.write("\n\n(e) ****** The prior probabilities of each class *******\n")
class_report_prob = classification_report(y_test, ys2_pred, target_names=bbc_data.target_names, output_dict=True)
# Want to compute the average for each class seperately by using the total value of which was 445
prob_total = class_report_prob['macro avg']['support'] 
business_prob = (class_report_prob['business']['support']/prob_total)
entertainment_prob =(class_report_prob['entertainment']['support']/prob_total)
politics_prob = (class_report_prob['politics']['support']/prob_total)
sport_prob = (class_report_prob['sport']['support']/prob_total)
tech_prob = (class_report_prob['tech']['support']/prob_total)
prior_prob = pd.DataFrame({business_prob, entertainment_prob, politics_prob, sport_prob, tech_prob}, index = ["Business", "Entertainment", "Politics", "Sports", "Tech"])
f.write(tabulate(prior_prob, headers=["Class", "Probability"], tablefmt="grid"))

    # Task 1.7 f
words = " ".join(vocabulary).split()
f.write("\n\n(f) The size in the vocabulary is: " +str(len(words)))

    #Task 1.7 g
f.write("\n\n(g) The number of word tokens in each class is:\n")
word_tokens = []
table_headers = ["Class" , "Word-Tokens"]
for i in range(len(x_labels)):
    words_class = np.sum(get_vector(BBC_Y, bbc_data_transformed, i))
    words = (x_labels[i]) +": " + (str(words_class)) +"\n"
    data1 = x_labels[i]
    data2 = (words_class)
    column = data1, data2
    word_tokens.append(column)

f.write(tabulate(word_tokens, tablefmt="grid", headers =table_headers ,stralign="right", numalign="right"))

    #Task 1.7 h 
f.write("\n\n(h) The number of word tokens in the whole corpus is: ")
words_corpus =str(sum(map(np.sum, bbc_data_transformed)))
f.write(words_corpus)

    #Task 1.7 i 
f.write("\n\n(i) Number and percentage of words with a frequency of zero in each class :\n ")

freq_table = []
table_headers = ["Class", "Words", "Percentage"]
for i in range(len(x_labels)):
    total_words = get_vector(BBC_Y, bbc_data_transformed, i)
    nonzerofreq_words  = np.count_nonzero(total_words.toarray())
    zerofreq_words = total_words.toarray().size - nonzerofreq_words
    percentage = "{:.2f}".format((zerofreq_words/total_words.toarray().size) * 100)
    formatted_percentage =  str(percentage) + " %"
    data_1 = x_labels[i]
    data2 = zerofreq_words
    data3 = formatted_percentage
    column = data_1, data2, data3
    freq_table.append(column)

f.write(tabulate(freq_table, tablefmt="grid", headers=table_headers))
            
 # Task 1.7 j    
f.write("\n\n(j) Number and percentage of words with a frequency of one in entire corpus :\n ")

words_corpus = bbc_data_transformed.toarray()
onefreq_words = np.count_nonzero(total_words.toarray()==1)
percentage = "{:.2f}".format((onefreq_words/total_words.toarray().size) * 100)
formatted_percentage =  str(percentage) + " %"
f.write("\n Number of words: " + str(onefreq_words)  + "\n")
f.write(" Percentage of words: " + formatted_percentage + "\n")

    # Task 1.7 k
f.write("\n\n(k) 2 favourite words and their log prob:\n\n ")

word1 = "potato"
word2 = "zombies"

vocabularylist = vectorizer.get_feature_names_out()
fav1 = np.where(vocabularylist == word1)[0][0]
fav2 = np.where(vocabularylist == word2)[0][0]

    # First fav word
business_logprob = classifier_MNBs2.feature_log_prob_[0][fav1]
entertainment_logprob = classifier_MNBs2.feature_log_prob_[1][fav1]
politics_logprob = classifier_MNBs2.feature_log_prob_[2][fav1]
sports_logprob = classifier_MNBs2.feature_log_prob_[3][fav1]
tech_logprob = classifier_MNBs2.feature_log_prob_[4][fav1]
logprob1 = business_logprob + entertainment_logprob + politics_logprob + sports_logprob + tech_logprob

f.write("Favourite word 1: " + word1 + "\n")
table_headers = ["Class" , "Log prob"]
table1 = pd.DataFrame({business_logprob, entertainment_logprob, politics_logprob, sports_logprob, tech_logprob}, index = x_labels)
f.write(tabulate(table1, headers = table_headers, tablefmt = "grid"))

    # Second fav word
business_logprob = classifier_MNBs2.feature_log_prob_[0][fav2]
entertainment_logprob = classifier_MNBs2.feature_log_prob_[1][fav2]
politics_logprob = classifier_MNBs2.feature_log_prob_[2][fav2]
sports_logprob = classifier_MNBs2.feature_log_prob_[3][fav2]
tech_logprob = classifier_MNBs2.feature_log_prob_[4][fav2]

f.write("\n\n" + "Favourite word 2: " + word2 + "\n")
table_headers = ["Class" , "Log prob"]
table2 = pd.DataFrame({business_logprob, entertainment_logprob, politics_logprob, sports_logprob, tech_logprob}, index = x_labels)
f.write(tabulate(table2, headers = table_headers, tablefmt = "grid"))